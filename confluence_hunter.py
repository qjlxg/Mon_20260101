import pandas as pd
import os
import glob
from datetime import datetime

# --- é…ç½®åŒº ---
RESULTS_DIR = 'results'
REPORT_DIR = 'reports'
# æˆ˜æ³•åç§°ç¿»è¯‘ï¼ˆå¯¹åº”ä½ çš„ 16 ä¸ªæ–‡ä»¶å¤¹åï¼‰
STRATEGY_NAMES = {
    'macd_bottom': 'MACDæŠ„åº•',
    'duck_head': 'è€é¸­å¤´',
    'three_in_one': 'ä¸‰ä½ä¸€ä½“',
    'pregnancy_line': 'åº•éƒ¨å­•çº¿',
    'single_yang': 'å•é˜³ä¸ç ´',
    'limit_pullback': 'æ¶¨åœå›è°ƒ',
    'golden_pit': 'é»„é‡‘å‘',
    'grass_fly': 'è‰ä¸Šé£',
    'limit_break': 'æ¶¨åœç ´ä½',
    'double_plate': 'é˜´é˜³åŒæ¿',
    'horse_back': 'æ´—ç›˜å›é©¬æª',
    'hot_money': 'æ¸¸èµ„å›è°ƒ',
    'wave_bottom': 'æ³¢åŠ¨æŠ„åº•',
    'no_loss': 'ç‰›æ•£ä¸äºé’±',
    'chase_rise': 'é«˜æ‰‹è¿½æ¶¨',
    'inst_swing': 'æœºæ„æ³¢æ®µ'
}

def run_confluence_analysis():
    date_str = datetime.now().strftime('%Y-%m-%d')
    all_picks = []

    # 1. æ‰«æç»“æœæ–‡ä»¶å¤¹
    if not os.path.exists(RESULTS_DIR):
        print("æœªå‘ç° results ç›®å½•ï¼Œè¯·å…ˆè¿è¡Œæˆ˜æ³•å¼•æ“ã€‚")
        return

    print(f"æ­£åœ¨åˆ†æ {date_str} çš„æˆ˜æ³•å…±æŒ¯æƒ…å†µ...")

    # 2. è¯»å–æ¯ä¸ªæˆ˜æ³•äº§å‡ºçš„æœ€æ–° CSV
    for folder_name, chinese_name in STRATEGY_NAMES.items():
        folder_path = os.path.join(RESULTS_DIR, folder_name)
        if not os.path.exists(folder_path):
            continue
            
        # å¯»æ‰¾å½“å¤©çš„æ–‡ä»¶
        pattern = os.path.join(folder_path, f"{folder_name}_{date_str}.csv")
        files = glob.glob(pattern)
        
        for f in files:
            try:
                df = pd.read_csv(f, dtype={'code': str})
                if df.empty: continue
                # è®°å½•æ¯åªè‚¡ç¥¨å±äºå“ªä¸ªæˆ˜æ³•
                df['strategy'] = chinese_name
                all_picks.append(df)
            except Exception as e:
                print(f"è¯»å– {f} å‡ºé”™: {e}")

    if not all_picks:
        print("ä»Šæ—¥æ— ä»»ä½•æˆ˜æ³•é€‰å‡ºè‚¡ç¥¨ã€‚")
        return

    # 3. åˆå¹¶æ‰€æœ‰ç»“æœ
    full_df = pd.concat(all_picks, ignore_index=True)

    # 4. è®¡ç®—å…±æŒ¯å¼ºåº¦ (Confluence Count)
    # æŒ‰ä»£ç å’Œåç§°åˆ†ç»„ï¼Œç»Ÿè®¡å‡ºç°äº†å¤šå°‘æ¬¡
    confluence = full_df.groupby(['code', 'name']).agg({
        'strategy': lambda x: ' + '.join(list(x)),
        'price': 'last'
    }).reset_index()
    
    confluence['count'] = confluence['strategy'].apply(lambda x: len(x.split(' + ')))
    
    # æŒ‰å…±æŒ¯æ¬¡æ•°é™åºæ’åˆ—
    confluence = confluence.sort_values(by='count', ascending=False)
    confluence.rename(columns={'strategy': 'å‘½ä¸­æˆ˜æ³•', 'count': 'å…±æŒ¯å¼ºåº¦', 'price': 'æ”¶ç›˜ä»·', 'code': 'ä»£ç ', 'name': 'åç§°'}, inplace=True)

    # 5. ä¿å­˜ç»“æœ
    if not os.path.exists(REPORT_DIR):
        os.makedirs(REPORT_DIR)

    # ä¿å­˜ CSV
    csv_path = os.path.join(REPORT_DIR, f"confluence_{date_str}.csv")
    confluence.to_csv(csv_path, index=False, encoding='utf-8-sig')

    # 6. ç”Ÿæˆ Markdown å¤ç›˜æŠ¥å‘Š (ç¾åŒ–ç‰ˆ)
    md_path = os.path.join(REPORT_DIR, f"report_{date_str}.md")
    with open(md_path, 'w', encoding='utf-8') as f:
        f.write(f"# 16æˆ˜æ³•å…±æŒ¯å¤ç›˜æŠ¥å‘Š ({date_str})\n\n")
        f.write(f"> è‡ªåŠ¨åŒ–ç³»ç»Ÿå·²å®Œæˆå…¨å¸‚åœºæ‰«æã€‚ä»Šæ—¥å…±é€‰å‡º **{len(confluence)}** åªç›®æ ‡è‚¡ã€‚\n\n")
        f.write("## ğŸ† å¼ºå…±æŒ¯å€™é€‰ (2é‡åŠä»¥ä¸Šå…±æŒ¯)\n\n")
        
        strong = confluence[confluence['å…±æŒ¯å¼ºåº¦'] >= 2]
        if not strong.empty:
            f.write(strong.to_markdown(index=False))
        else:
            f.write("ä»Šæ—¥æš‚æ— å¤šé‡å…±æŒ¯æ ‡çš„ã€‚")
            
        f.write("\n\n## ğŸ” å…¨é‡é€‰è‚¡æ¸…å•\n\n")
        f.write(confluence.to_markdown(index=False))

    print(f"âœ… åˆ†æå®Œæˆï¼å…±æŒ¯æŠ¥å‘Šå·²ç”Ÿæˆè‡³: {REPORT_DIR}")

if __name__ == "__main__":
    run_confluence_analysis()
